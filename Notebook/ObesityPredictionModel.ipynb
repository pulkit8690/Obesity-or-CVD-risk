{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obesity Risk Prediction Model\n",
    "\n",
    "This notebook builds and trains a Random Forest model to predict obesity risk based on various lifestyle and health factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../data/ObesityDataSet.csv')\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop('NObeyesdad', axis=1)\n",
    "y = data['NObeyesdad']\n",
    "\n",
    "# Split numeric and categorical features\n",
    "numeric_features = X.select_dtypes(exclude=['object']).columns\n",
    "string_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode target variable\n",
    "label = LabelEncoder()\n",
    "y_train = label.fit_transform(y_train)\n",
    "y_test = label.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values[missing_values > 0])\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = data.duplicated().sum()\n",
    "print(\"\\nNumber of Duplicate Rows:\", duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "print(\"Duplicates removed. New dataset shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in categorical columns (to detect inconsistencies)\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "unique_values = {col: data[col].unique() for col in categorical_columns}\n",
    "\n",
    "print(\"\\nUnique Values in Categorical Columns:\")\n",
    "for col, values in unique_values.items():\n",
    "    print(f\"{col}: {values[:5]}...\")  # Display only first 5 unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check summary statistics for numerical columns (to detect anomalies)\n",
    "numerical_summary = data.describe()\n",
    "print(\"\\nNumerical Summary:\\n\", numerical_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "plt.figure(figsize=(10, 4))\n",
    "data['NObeyesdad'].value_counts().plot(kind='bar')\n",
    "plt.xticks(rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String features\n",
    "for col in string_features:\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    data[col].value_counts().plot(kind='bar')\n",
    "    plt.xticks(rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric features\n",
    "for col in numeric_features:\n",
    "\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    sns.kdeplot(data, x=col)\n",
    "    plt.title(col)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    sns.boxplot(data, x=col)\n",
    "    plt.title(col)\n",
    "    plt.xticks(rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipelines for numeric and categorical features\n",
    "string_transformer = Pipeline([\n",
    "    ('One_Hot_Encoder', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('Power_Transformer', PowerTransformer())\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numeric_transformer', numeric_transformer, numeric_features),\n",
    "    ('string_transformer', string_transformer, string_features)\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train Best Model\n",
    "\n",
    "Using the best hyperparameters found through Optuna optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the best model with optimal hyperparameters\n",
    "best_model = RandomForestClassifier(\n",
    "    n_estimators=102,\n",
    "    criterion='log_loss',\n",
    "    max_depth=11,\n",
    "    max_features=None,\n",
    "    min_samples_split=6,\n",
    "    min_samples_leaf=3,\n",
    "    max_samples=0.9092488038970724,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create pipeline with preprocessor and model\n",
    "best_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', best_model)\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "best_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_preds = best_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_preds):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_preds, average='weighted'):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_preds, average='weighted'):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_preds, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after preprocessing\n",
    "preprocessor_feature_names = best_pipe.named_steps['preprocessor'].get_feature_names_out()\n",
    "feature_names = np.array([s.split('__')[1] for s in preprocessor_feature_names])\n",
    "\n",
    "# Get feature importances\n",
    "importances = best_pipe.named_steps['model'].feature_importances_\n",
    "\n",
    "# Create DataFrame of feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(data=feature_importances_df, x='Feature', y='Importance')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Feature Importance in Obesity Risk Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire pipeline (including preprocessor and model)\n",
    "joblib.dump(best_pipe, '../Model/obesity_prediction_model.joblib')\n",
    "\n",
    "# Save the label encoder for target variable\n",
    "joblib.dump(label, '../Model/target_encoder.joblib')\n",
    "\n",
    "print(\"Model and encoder saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
